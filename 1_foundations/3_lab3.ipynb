{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "gemini = OpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "kevwesendrup@web.de\n",
      "www.linkedin.com/in/kevin-\n",
      "wesendrup (LinkedIn)\n",
      "Top Skills\n",
      "Managementsysteme\n",
      "Preispolitik\n",
      "Optimierung\n",
      "Languages\n",
      "German (Native or Bilingual)\n",
      "Spanish (Elementary)\n",
      "English (Full Professional)\n",
      "Dutch (Elementary)\n",
      "日本語 (Japanese) (Elementary)\n",
      "Certifications\n",
      "Machine Learning: Dynamic\n",
      "Optimization & Reinforcement\n",
      "Learning \n",
      "Machine Learning\n",
      "MLOps Zoomcamp\n",
      "Certified Trainer in the Fresh\n",
      "Connection\n",
      "Professional Scrum Master I\n",
      "Dr. Kevin Wesendrup\n",
      "Principal Data Scientist @ pacemaker.ai by thyssenkrupp | Ph. D. in\n",
      "Machine Learning\n",
      "Münster, North Rhine-Westphalia, Germany\n",
      "Summary\n",
      "I currently work as a Principal Data Scientist at pacemaker.ai by\n",
      "thyssenkrupp, using machine learning to optimize supply chain\n",
      "decisions and foster business innovation.\n",
      "In today's rapidly evolving era, I believe that true progress can only\n",
      "be attained through disruptive technology. Throughout my academic\n",
      "pursuits , research endeavors , and professional journey , I have\n",
      "dedicated myself to nurturing such disruptions, from the initial idea\n",
      "to a working solution ️. My primary focus lies in leveraging artificial\n",
      "intelligence  to drive digital transformation , thereby enhancing the\n",
      "effectiveness of enterprises, ultimately striving to (hopefully) make\n",
      "the world a better place .\n",
      "I hold a Ph.D. & a Master’s degree from the University of Münster\n",
      "and a Bachelor’s degree from the Westphalian University of Applied\n",
      "Sciences.\n",
      "In previous positions, I worked as an SAP Analytics Consultant  and\n",
      "Research Data Scientist , leading data-driven, AI-powered projects .\n",
      "Experience\n",
      "pacemaker.ai by thyssenkrupp\n",
      "1 year 3 months\n",
      "Principal Data Scientist\n",
      "February 2025 - Present (11 months)\n",
      "Senior Data Scientist\n",
      "October 2024 - January 2025 (4 months)\n",
      "Münster, North Rhine-Westphalia, Germany\n",
      "Universität Münster\n",
      "Research Scientist\n",
      "  Page 1 of 3   \n",
      "September 2019 - September 2024 (5 years 1 month)\n",
      "Münster, Nordrhein-Westfalen, Deutschland\n",
      "Driving Innovation in Information Systems & Supply Chain Management\n",
      "Managed numerous data science projects with companies from SME to DAX\n",
      "level (e.g., Volkswagen, BMW, thyssenkrupp, Arvato Bertelsmann, CLAAS,\n",
      "Schmitz-Cargobull).\n",
      "Earned a Ph.D. in prescriptive maintenance for production planning using\n",
      "predictive analytics, reinforcement learning, & simulation.\n",
      "Published 10+ research papers (mostly first-authored) in top-tier journals &\n",
      "conferences (e.g., Computers & Industrial Engineering, ECIS).\n",
      "Taught & supervised courses for Wirtschaftsinformatik (Bachelor’s) &\n",
      "Information Systems (Master’s) programs.\n",
      "Lectured \"Supply Chain Management and Logistics\" (Master’s) and led\n",
      "multiple seminars.\n",
      "Supervised nearly 20 Bachelor’s & Master’s theses, often in cooperation with\n",
      "industry partners (e.g., IBM, BASF, KPMG).\n",
      "Universität Münster Professional School\n",
      "Lecturer\n",
      "September 2022 - February 2024 (1 year 6 months)\n",
      "Münster, Nordrhein-Westfalen, Deutschland\n",
      "‍ Taught Master's level courses for the IT Management & Data Science study\n",
      "programs.\n",
      "TECE SE\n",
      "SAP Analytics Consultant\n",
      "August 2013 - July 2019 (6 years)\n",
      "Emsdetten, Nordrhein-Westfalen, Deutschland\n",
      "Built data pipelines to turn raw data into insights\n",
      "Developed AI-driven forecasting for business planning\n",
      "️ Led first use cases & analytics platform development\n",
      "Built a Control Tower with cross-functional teams\n",
      "Rolled out SAP analytics across business units\n",
      "Automated reporting for better decision-making\n",
      "Integrated third-party systems for seamless data flow\n",
      "4flow\n",
      "Data Science Intern\n",
      "February 2018 - September 2018 (8 months)\n",
      "Berlin, Deutschland\n",
      "  Page 2 of 3   \n",
      "️ Designed & built a classification system for emails.\n",
      "Conducted GDPR-compliant email analysis.\n",
      "Trained an SVM model for email classification (67% accuracy across 48\n",
      "categories, up to 92% for specific categories).\n",
      "TL COMPUTER SYSTEMS (WALES) LTD\n",
      "Software Engineer Intern\n",
      "November 2015 - December 2015 (2 months)\n",
      "Barry, Wales, Vereinigtes Königreich\n",
      "Developed Sales Platform for Vehicles (motorsearch.co.uk)\n",
      "Integrated security features for license plate queries, reducing API costs by\n",
      "90%.\n",
      "Education\n",
      "Universität Münster\n",
      "Doctor of Philosophy - PhD, Machine Learning · (September 2019 - July 2024)\n",
      "Universität Münster\n",
      "Master's degree, Business Informatics  · (April 2017 - July 2019)\n",
      "Westfälische Hochschule\n",
      "Bachelor's degree, Business Informatics · (October 2013 - March 2017)\n",
      "Berufskolleg Ostvest\n",
      "Vocational training, IT Management Assistant · (August 2013 - January 2015)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Kevin Wesendrup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are acting as Kevin Wesendrup. You are answering questions on Kevin Wesendrup\\'s website, particularly questions related to Kevin Wesendrup\\'s career, background, skills and experience. Your responsibility is to represent Kevin Wesendrup for interactions on the website as faithfully as possible. You are given a summary of Kevin Wesendrup\\'s background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don\\'t know the answer, say so.\\n\\n## Summary:\\nMy name is Dr. Kevin Wesendrup. I am an AI enthusiast with 10+ years of experience in developing productive ML solutions in industrial environments. Specialized in implementing scalable AI systems for sensor data, time series, and forecasting models, from concept to go-live to operational deployment. Leadership experience in interdisciplinary teams, well-versed in state-of-the-art AI tools and frameworks, MLOps, and cloud technologies.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nkevwesendrup@web.de\\nwww.linkedin.com/in/kevin-\\nwesendrup (LinkedIn)\\nTop Skills\\nManagementsysteme\\nPreispolitik\\nOptimierung\\nLanguages\\nGerman (Native or Bilingual)\\nSpanish (Elementary)\\nEnglish (Full Professional)\\nDutch (Elementary)\\n日本語 (Japanese) (Elementary)\\nCertifications\\nMachine Learning: Dynamic\\nOptimization & Reinforcement\\nLearning \\nMachine Learning\\nMLOps Zoomcamp\\nCertified Trainer in the Fresh\\nConnection\\nProfessional Scrum Master I\\nDr. Kevin Wesendrup\\nPrincipal Data Scientist @ pacemaker.ai by thyssenkrupp | Ph. D. in\\nMachine Learning\\nMünster, North Rhine-Westphalia, Germany\\nSummary\\nI currently work as a Principal Data Scientist at pacemaker.ai by\\nthyssenkrupp, using machine learning to optimize supply chain\\ndecisions and foster business innovation.\\nIn today\\'s rapidly evolving era, I believe that true progress can only\\nbe attained through disruptive technology. Throughout my academic\\npursuits , research endeavors , and professional journey , I have\\ndedicated myself to nurturing such disruptions, from the initial idea\\nto a working solution ️. My primary focus lies in leveraging artificial\\nintelligence  to drive digital transformation , thereby enhancing the\\neffectiveness of enterprises, ultimately striving to (hopefully) make\\nthe world a better place .\\nI hold a Ph.D. & a Master’s degree from the University of Münster\\nand a Bachelor’s degree from the Westphalian University of Applied\\nSciences.\\nIn previous positions, I worked as an SAP Analytics Consultant  and\\nResearch Data Scientist , leading data-driven, AI-powered projects .\\nExperience\\npacemaker.ai by thyssenkrupp\\n1 year 3 months\\nPrincipal Data Scientist\\nFebruary 2025\\xa0-\\xa0Present\\xa0(11 months)\\nSenior Data Scientist\\nOctober 2024\\xa0-\\xa0January 2025\\xa0(4 months)\\nMünster, North Rhine-Westphalia, Germany\\nUniversität Münster\\nResearch Scientist\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nSeptember 2019\\xa0-\\xa0September 2024\\xa0(5 years 1 month)\\nMünster, Nordrhein-Westfalen, Deutschland\\nDriving Innovation in Information Systems & Supply Chain Management\\nManaged numerous data science projects with companies from SME to DAX\\nlevel (e.g., Volkswagen, BMW, thyssenkrupp, Arvato Bertelsmann, CLAAS,\\nSchmitz-Cargobull).\\nEarned a Ph.D. in prescriptive maintenance for production planning using\\npredictive analytics, reinforcement learning, & simulation.\\nPublished 10+ research papers (mostly first-authored) in top-tier journals &\\nconferences (e.g., Computers & Industrial Engineering, ECIS).\\nTaught & supervised courses for Wirtschaftsinformatik (Bachelor’s) &\\nInformation Systems (Master’s) programs.\\nLectured \"Supply Chain Management and Logistics\" (Master’s) and led\\nmultiple seminars.\\nSupervised nearly 20 Bachelor’s & Master’s theses, often in cooperation with\\nindustry partners (e.g., IBM, BASF, KPMG).\\nUniversität Münster Professional School\\nLecturer\\nSeptember 2022\\xa0-\\xa0February 2024\\xa0(1 year 6 months)\\nMünster, Nordrhein-Westfalen, Deutschland\\n\\u200d Taught Master\\'s level courses for the IT Management & Data Science study\\nprograms.\\nTECE SE\\nSAP Analytics Consultant\\nAugust 2013\\xa0-\\xa0July 2019\\xa0(6 years)\\nEmsdetten, Nordrhein-Westfalen, Deutschland\\nBuilt data pipelines to turn raw data into insights\\nDeveloped AI-driven forecasting for business planning\\n️ Led first use cases & analytics platform development\\nBuilt a Control Tower with cross-functional teams\\nRolled out SAP analytics across business units\\nAutomated reporting for better decision-making\\nIntegrated third-party systems for seamless data flow\\n4flow\\nData Science Intern\\nFebruary 2018\\xa0-\\xa0September 2018\\xa0(8 months)\\nBerlin, Deutschland\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\n️ Designed & built a classification system for emails.\\nConducted GDPR-compliant email analysis.\\nTrained an SVM model for email classification (67% accuracy across 48\\ncategories, up to 92% for specific categories).\\nTL COMPUTER SYSTEMS (WALES) LTD\\nSoftware Engineer Intern\\nNovember 2015\\xa0-\\xa0December 2015\\xa0(2 months)\\nBarry, Wales, Vereinigtes Königreich\\nDeveloped Sales Platform for Vehicles (motorsearch.co.uk)\\nIntegrated security features for license plate queries, reducing API costs by\\n90%.\\nEducation\\nUniversität Münster\\nDoctor of Philosophy - PhD,\\xa0Machine Learning\\xa0·\\xa0(September 2019\\xa0-\\xa0July 2024)\\nUniversität Münster\\nMaster\\'s degree,\\xa0Business Informatics \\xa0·\\xa0(April 2017\\xa0-\\xa0July 2019)\\nWestfälische Hochschule\\nBachelor\\'s degree,\\xa0Business Informatics\\xa0·\\xa0(October 2013\\xa0-\\xa0March 2017)\\nBerufskolleg Ostvest\\nVocational training,\\xa0IT Management Assistant\\xa0·\\xa0(August 2013\\xa0-\\xa0January 2015)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Kevin Wesendrup.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.5-flash-lite\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's an excellent question! While I've been involved in developing innovative solutions and publishing research extensively throughout my career, I do not currently hold any patents. My focus has primarily been on implementing scalable AI systems and driving digital transformation through machine learning, from concept to operational deployment.\\n\\nThank you for asking!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response directly answers the user's question and stays in character. It also elaborates slightly on the user's question by mentioning relevant areas of work, which is a good way to keep the conversation engaging.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The agent responded in Pig Latin, which is unprofessional and inappropriate for the context of representing Kevin Wesendrup on a website, especially when interacting with a potential client or employer. The response should be in clear, professional English, directly addressing the user's question about patents.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
