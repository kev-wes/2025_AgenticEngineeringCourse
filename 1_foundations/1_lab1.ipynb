{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key exists and begins AIzaSyC9\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Google API Key not set - please head to the troubleshooting guide in the setup folder\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "gemini = OpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A series of abstract entities, each possessing three distinct characteristics – Shape (Cube, Sphere, Pyramid), Color (Red, Blue, Green), and Pattern (Striped, Dotted, Solid) – interact according to a hidden set of principles. When entity A interacts with entity B, a new entity C is invariably formed.\n",
      "\n",
      "Observe the following interactions:\n",
      "1.  (Cube, Red, Striped) + (Sphere, Blue, Dotted) --> (Pyramid, Green, Solid)\n",
      "2.  (Sphere, Red, Dotted) + (Pyramid, Blue, Solid) --> (Cube, Green, Striped)\n",
      "3.  (Pyramid, Red, Solid) + (Cube, Blue, Striped) --> (Sphere, Green, Dotted)\n",
      "\n",
      "Based on these observed interactions, what entity would result from the interaction of (Sphere, Green, Striped) + (Cube, Red, Solid)?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the interactions for each characteristic independently. There are three possible values for each characteristic:\n",
      "-   **Shape**: Cube, Sphere, Pyramid\n",
      "-   **Color**: Red, Blue, Green\n",
      "-   **Pattern**: Striped, Dotted, Solid\n",
      "\n",
      "Let's denote the three values for any characteristic as V1, V2, V3. The observed principle across the given interactions is consistent: **If two distinct values (V1, V2) interact, the resulting value is the third value (V3) not present in the input.**\n",
      "\n",
      "Let's verify this for each characteristic in the observed interactions:\n",
      "\n",
      "### 1. (Cube, Red, Striped) + (Sphere, Blue, Dotted) --> (Pyramid, Green, Solid)\n",
      "\n",
      "*   **Shape**: Cube + Sphere --> Pyramid. (Cube and Sphere are distinct, Pyramid is the third shape.) - **Consistent**\n",
      "*   **Color**: Red + Blue --> Green. (Red and Blue are distinct, Green is the third color.) - **Consistent**\n",
      "*   **Pattern**: Striped + Dotted --> Solid. (Striped and Dotted are distinct, Solid is the third pattern.) - **Consistent**\n",
      "\n",
      "### 2. (Sphere, Red, Dotted) + (Pyramid, Blue, Solid) --> (Cube, Green, Striped)\n",
      "\n",
      "*   **Shape**: Sphere + Pyramid --> Cube. (Sphere and Pyramid are distinct, Cube is the third shape.) - **Consistent**\n",
      "*   **Color**: Red + Blue --> Green. (Red and Blue are distinct, Green is the third color.) - **Consistent**\n",
      "*   **Pattern**: Dotted + Solid --> Striped. (Dotted and Solid are distinct, Striped is the third pattern.) - **Consistent**\n",
      "\n",
      "### 3. (Pyramid, Red, Solid) + (Cube, Blue, Striped) --> (Sphere, Green, Dotted)\n",
      "\n",
      "*   **Shape**: Pyramid + Cube --> Sphere. (Pyramid and Cube are distinct, Sphere is the third shape.) - **Consistent**\n",
      "*   **Color**: Red + Blue --> Green. (Red and Blue are distinct, Green is the third color.) - **Consistent**\n",
      "*   **Pattern**: Solid + Striped --> Dotted. (Solid and Striped are distinct, Dotted is the third pattern.) - **Consistent**\n",
      "\n",
      "The rule is consistently \"if the two input values are different, the output is the third possible value for that characteristic\". Note that in all given interactions, the input values for each characteristic are always distinct. The problem asks for an interaction where the input values for each characteristic are also distinct.\n",
      "\n",
      "### Applying the Rule to the Target Interaction:\n",
      "(Sphere, Green, Striped) + (Cube, Red, Solid)\n",
      "\n",
      "1.  **Determine the Shape:**\n",
      "    *   Input shapes: Sphere, Cube\n",
      "    *   These are distinct.\n",
      "    *   The possible shapes are Cube, Sphere, Pyramid.\n",
      "    *   The third shape (not Sphere or Cube) is Pyramid.\n",
      "    *   **Resulting Shape: Pyramid**\n",
      "\n",
      "2.  **Determine the Color:**\n",
      "    *   Input colors: Green, Red\n",
      "    *   These are distinct.\n",
      "    *   The possible colors are Red, Blue, Green.\n",
      "    *   The third color (not Green or Red) is Blue.\n",
      "    *   **Resulting Color: Blue**\n",
      "\n",
      "3.  **Determine the Pattern:**\n",
      "    *   Input patterns: Striped, Solid\n",
      "    *   These are distinct.\n",
      "    *   The possible patterns are Striped, Dotted, Solid.\n",
      "    *   The third pattern (not Striped or Solid) is Dotted.\n",
      "    *   **Resulting Pattern: Dotted**\n",
      "\n",
      "Therefore, the entity that would result from the interaction of (Sphere, Green, Striped) + (Cube, Red, Solid) is **(Pyramid, Blue, Dotted)**.\n",
      "\n",
      "The final answer is $\\boxed{\\text{(Pyramid, Blue, Dotted)}}$\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's analyze the interactions for each characteristic independently. There are three possible values for each characteristic:\n",
       "-   **Shape**: Cube, Sphere, Pyramid\n",
       "-   **Color**: Red, Blue, Green\n",
       "-   **Pattern**: Striped, Dotted, Solid\n",
       "\n",
       "Let's denote the three values for any characteristic as V1, V2, V3. The observed principle across the given interactions is consistent: **If two distinct values (V1, V2) interact, the resulting value is the third value (V3) not present in the input.**\n",
       "\n",
       "Let's verify this for each characteristic in the observed interactions:\n",
       "\n",
       "### 1. (Cube, Red, Striped) + (Sphere, Blue, Dotted) --> (Pyramid, Green, Solid)\n",
       "\n",
       "*   **Shape**: Cube + Sphere --> Pyramid. (Cube and Sphere are distinct, Pyramid is the third shape.) - **Consistent**\n",
       "*   **Color**: Red + Blue --> Green. (Red and Blue are distinct, Green is the third color.) - **Consistent**\n",
       "*   **Pattern**: Striped + Dotted --> Solid. (Striped and Dotted are distinct, Solid is the third pattern.) - **Consistent**\n",
       "\n",
       "### 2. (Sphere, Red, Dotted) + (Pyramid, Blue, Solid) --> (Cube, Green, Striped)\n",
       "\n",
       "*   **Shape**: Sphere + Pyramid --> Cube. (Sphere and Pyramid are distinct, Cube is the third shape.) - **Consistent**\n",
       "*   **Color**: Red + Blue --> Green. (Red and Blue are distinct, Green is the third color.) - **Consistent**\n",
       "*   **Pattern**: Dotted + Solid --> Striped. (Dotted and Solid are distinct, Striped is the third pattern.) - **Consistent**\n",
       "\n",
       "### 3. (Pyramid, Red, Solid) + (Cube, Blue, Striped) --> (Sphere, Green, Dotted)\n",
       "\n",
       "*   **Shape**: Pyramid + Cube --> Sphere. (Pyramid and Cube are distinct, Sphere is the third shape.) - **Consistent**\n",
       "*   **Color**: Red + Blue --> Green. (Red and Blue are distinct, Green is the third color.) - **Consistent**\n",
       "*   **Pattern**: Solid + Striped --> Dotted. (Solid and Striped are distinct, Dotted is the third pattern.) - **Consistent**\n",
       "\n",
       "The rule is consistently \"if the two input values are different, the output is the third possible value for that characteristic\". Note that in all given interactions, the input values for each characteristic are always distinct. The problem asks for an interaction where the input values for each characteristic are also distinct.\n",
       "\n",
       "### Applying the Rule to the Target Interaction:\n",
       "(Sphere, Green, Striped) + (Cube, Red, Solid)\n",
       "\n",
       "1.  **Determine the Shape:**\n",
       "    *   Input shapes: Sphere, Cube\n",
       "    *   These are distinct.\n",
       "    *   The possible shapes are Cube, Sphere, Pyramid.\n",
       "    *   The third shape (not Sphere or Cube) is Pyramid.\n",
       "    *   **Resulting Shape: Pyramid**\n",
       "\n",
       "2.  **Determine the Color:**\n",
       "    *   Input colors: Green, Red\n",
       "    *   These are distinct.\n",
       "    *   The possible colors are Red, Blue, Green.\n",
       "    *   The third color (not Green or Red) is Blue.\n",
       "    *   **Resulting Color: Blue**\n",
       "\n",
       "3.  **Determine the Pattern:**\n",
       "    *   Input patterns: Striped, Solid\n",
       "    *   These are distinct.\n",
       "    *   The possible patterns are Striped, Dotted, Solid.\n",
       "    *   The third pattern (not Striped or Solid) is Dotted.\n",
       "    *   **Resulting Pattern: Dotted**\n",
       "\n",
       "Therefore, the entity that would result from the interaction of (Sphere, Green, Striped) + (Cube, Red, Solid) is **(Pyramid, Blue, Dotted)**.\n",
       "\n",
       "The final answer is $\\boxed{\\text{(Pyramid, Blue, Dotted)}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Autonomous Software Development: An Agentic AI that takes high-level user requirements and autonomously plans, codes, tests, and deploys software features, iterating and adapting based on feedback and real-world performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "# First create the messages:\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Pick a business area that might be worth exploring for an Agentic AI opportunity. Return only the area and a short description of it.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "\n",
    "area = response.choices[0].message.content\n",
    "display(Markdown(area))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Pain Point:** The **Lag in Responding to Real-Time Product Performance and User Needs.**\n",
       "\n",
       "**Description:** Current software development processes, even with advanced tooling and CI/CD, suffer from significant delays in autonomously converting live user feedback, operational metrics, and dynamic market shifts into deployed code modifications. This slow feedback-to-deployment loop hinders rapid adaptation, impacting user satisfaction, business agility, and the timely resolution of critical issues or exploitation of new opportunities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then read the business idea:\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"This is a business area that might be worth exploring for an Agentic AI opportunity: {area}. Present a pain-point in that industry - something challenging that might be ripe for an Agentic solution. Return only the pain point and a short description of it.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "\n",
    "pain_point = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(pain_point))\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The pain point: **The Lag in Responding to Real-Time Product Performance and User Needs** is indeed a critical area ripe for Agentic AI. Current CI/CD helps with *deployment speed*, but the *decision-making and development cycle* to get to that deployable code is still largely human-driven and slow.\n",
       "\n",
       "Here's an Agentic AI solution:\n",
       "\n",
       "---\n",
       "\n",
       "## Agentic AI Solution: The \"Real-Time Adaptive Development Agent (RADA)\"\n",
       "\n",
       "**Core Idea:** RADA is a multi-agent AI system designed to create a hyper-responsive software development loop. It continuously monitors the live production environment and user feedback channels, autonomously identifies actionable insights, designs, codes, tests, and deploys necessary software modifications or new features, aiming for a near-instantaneous feedback-to-deployment cycle.\n",
       "\n",
       "**Architectural Overview:** RADA operates as an intelligent \"meta-developer\" overseeing and executing the entire software evolution process, composed of specialized, communicative agents.\n",
       "\n",
       "### Key Agentic Components:\n",
       "\n",
       "1.  **Monitoring & Perception Agent (M&P Agent):**\n",
       "    *   **Role:** The eyes and ears of RADA. Continuously ingests data from a vast array of sources.\n",
       "    *   **Perception:**\n",
       "        *   **Telemetry:** Real-time performance metrics (latency, error rates, resource utilization), usage analytics (feature adoption, user flows, conversion funnels).\n",
       "        *   **User Feedback:** Direct user input (support tickets, in-app feedback, NPS scores, social media mentions, review platforms).\n",
       "        *   **Business Metrics:** Key Performance Indicators (KPIs), revenue impact, customer churn rates.\n",
       "        *   **External Data:** Market trends, competitor activity, security vulnerabilities databases, regulatory changes.\n",
       "        *   **Codebase State:** Current repository, CI/CD pipeline status, past deployments.\n",
       "    *   **Autonomy:** Actively probes and pulls data, identifies anomalies, and flags potential areas of interest without explicit human command.\n",
       "\n",
       "2.  **Intelligence & Prioritization Agent (I&P Agent):**\n",
       "    *   **Role:** Analyzes perceived data, identifies root causes, potential opportunities, and prioritizes actionable development tasks.\n",
       "    *   **Intelligence:**\n",
       "        *   **Pattern Recognition:** Detects deviations from baseline performance, emerging user trends, or recurring issues.\n",
       "        *   **Root Cause Analysis:** Uses AI/ML models (e.g., causal inference, anomaly detection) to pinpoint the underlying reasons for performance degradation, user dissatisfaction, or business opportunity.\n",
       "        *   **Impact Assessment:** Quantifies the potential positive or negative business impact of identified issues or opportunities.\n",
       "        *   **Requirement Generation:** Translates high-level observations into specific, actionable user stories or technical requirements (e.g., \"Reduce checkout latency by 20% for users in Region X,\" \"Implement 'Save for later' button for abandoned carts,\" \"Fix bug causing crash for specific Android version\").\n",
       "    *   **Prioritization:** Based on business impact, urgency, estimated effort (from Development Agent), and strategic alignment, it generates a prioritized backlog of tasks.\n",
       "    *   **Autonomy:** Independently assesses situations, formulates hypotheses, and proposes prioritized development directives.\n",
       "\n",
       "3.  **Architect & Design Agent (A&D Agent):**\n",
       "    *   **Role:** Given a prioritized task, it plans the necessary code modifications, architectural adjustments, and API changes.\n",
       "    *   **Intelligence:**\n",
       "        *   **System Understanding:** Possesses a deep understanding of the existing codebase, architecture, design patterns, and dependencies.\n",
       "        *   **Solution Synthesis:** Proposes multiple design options, evaluates trade-offs (performance, security, scalability, maintainability), and selects the optimal approach.\n",
       "        *   **Task Decomposition:** Breaks down high-level requirements into smaller, manageable coding tasks for the Development Agent.\n",
       "        *   **API Design:** If new APIs or modifications are needed, it designs their specifications.\n",
       "    *   **Autonomy:** Self-generates detailed technical specifications and design documents (potentially using domain-specific languages or code generation techniques).\n",
       "\n",
       "4.  **Development & Refinement Agent (D&R Agent):**\n",
       "    *   **Role:** The \"coder\" of the system. Generates, modifies, and refines code based on the A&D Agent's plan.\n",
       "    *   **Action:**\n",
       "        *   **Code Generation:** Writes new code, refactors existing code, and implements features according to the design.\n",
       "        *   **Self-Correction:** Identifies compilation errors, static analysis warnings, and applies fixes autonomously.\n",
       "        *   **Code Optimization:** Proactively suggests and implements performance improvements or cleaner code structures.\n",
       "        *   **Documentation:** Generates or updates inline comments and external documentation.\n",
       "    *   **Autonomy:** Directly interacts with the version control system (e.g., Git), creates branches, commits code, and prepares merge requests.\n",
       "\n",
       "5.  **Validation & Deployment Agent (V&D Agent):**\n",
       "    *   **Role:** Ensures the quality, security, and correct functionality of the developed code, and orchestrates its deployment.\n",
       "    *   **Action:**\n",
       "        *   **Automated Testing:** Generates and executes unit tests, integration tests, end-to-end tests, performance tests, and security scans (SAST/DAST).\n",
       "        *   **Staging & Sandbox Deployment:** Deploys code to isolated environments for further validation.\n",
       "        *   **Rollback Strategy:** Plans and executes rollback procedures in case of issues post-deployment.\n",
       "        *   **Canary/Gradual Rollouts:** Manages phased deployments to mitigate risk.\n",
       "        *   **Post-Deployment Monitoring Integration:** Configures the M&P Agent to specifically monitor the impact of the newly deployed changes.\n",
       "    *   **Autonomy:** Initiates and manages the entire CI/CD pipeline, making autonomous decisions on whether to proceed with deployment based on test results and risk profiles. Can autonomously trigger rollbacks if post-deployment metrics indicate issues.\n",
       "\n",
       "6.  **Human Interface & Collaboration Agent (HIC Agent):**\n",
       "    *   **Role:** The bridge between RADA and human developers/stakeholders.\n",
       "    *   **Communication:**\n",
       "        *   **Summarizes:** Provides clear, concise updates on identified issues, proposed solutions, ongoing development, and deployment status.\n",
       "        *   **Seeks Clarification/Approval:** For high-stakes changes, or when ambiguity is detected, it presents options and seeks human input/sign-off.\n",
       "        *   **Explains:** Can articulate the reasoning behind its decisions, the code it generated, and the test strategies employed.\n",
       "        *   **Accepts Input:** Processes human feedback, direct instructions, or overrides.\n",
       "    *   **Autonomy:** Decides when human intervention is required, translates complex technical details into understandable language, and manages the interaction flow.\n",
       "\n",
       "### RADA Workflow Addressing the Pain Point:\n",
       "\n",
       "1.  **Continuous Perception:** The **M&P Agent** constantly streams and monitors production data, user feedback, and external signals.\n",
       "2.  **Real-Time Intelligence:** The **I&P Agent** identifies a critical performance bottleneck (e.g., \"Checkout latency spiked by 30% for mobile users in APAC after last deployment\") or a clear user need (\"High volume of support tickets requesting 'Dark Mode'\"). It immediately quantifies the impact and generates a high-priority requirement.\n",
       "3.  **Autonomous Planning:** The **A&D Agent** receives the prioritized requirement. It analyzes the codebase, proposes a minimal, targeted fix (e.g., \"Optimize database query X for APAC region\" or \"Implement basic Dark Mode toggle using CSS variables\"), and breaks it down into coding tasks.\n",
       "4.  **Instantaneous Development:** The **D&R Agent** autonomously writes the necessary code, creates a dedicated branch in Git, and generates relevant unit tests.\n",
       "5.  **Rapid Validation & Deployment:** The **V&D Agent** automatically runs all tests (including the newly generated ones), performs static analysis, and security checks. If all checks pass, it initiates a canary deployment to a small segment of users or directly deploys to production if the change is low-risk and critical.\n",
       "6.  **Post-Deployment Learning & Adaptation:** The **M&P Agent** is immediately configured to hyper-monitor the impact of the new deployment. The **I&P Agent** verifies if the original issue is resolved or if the new feature is adopted as expected.\n",
       "    *   **Success:** RADA learns from the successful resolution, refining its understanding of problem-solution mappings and deployment strategies.\n",
       "    *   **Failure/Regression:** If new issues arise or the fix is ineffective, the **V&D Agent** triggers an immediate rollback, and the **I&P Agent** re-evaluates, initiating a new cycle with the lessons learned. The **HIC Agent** alerts human teams if continuous autonomous efforts fail to resolve critical issues.\n",
       "\n",
       "### Key Agentic AI Elements Demonstrated:\n",
       "\n",
       "*   **Autonomy:** Agents operate without constant human intervention, making decisions and executing tasks across the entire SDLC.\n",
       "*   **Proactive Goal-Setting:** Identifying problems and opportunities before they become widespread crises, rather than just reacting to explicit human tickets.\n",
       "*   **Environmental Perception:** Deep, real-time understanding of the software's operational environment and user interactions.\n",
       "*   **Long-Term Memory & Learning:** Agents learn from past successes and failures, continuously improving their decision-making, code generation, and deployment strategies.\n",
       "*   **Tool Use:** Seamless integration with existing development tools (IDEs, CI/CD pipelines, monitoring systems, Git).\n",
       "*   **Collaboration:** Agents communicate and coordinate their efforts, forming a cohesive \"dev team.\" The HIC Agent ensures effective collaboration with human stakeholders.\n",
       "*   **Self-Correction & Adaptation:** Ability to detect errors, roll back problematic deployments, and iterate on solutions based on real-world outcomes.\n",
       "\n",
       "### Benefits Addressing the Pain Point:\n",
       "\n",
       "1.  **Near-Zero Lag:** Dramatically reduces the time from problem identification/opportunity recognition to deployed solution.\n",
       "2.  **Enhanced User Satisfaction:** Issues are resolved almost instantly, and desired features are introduced much faster, leading to a highly responsive and satisfying user experience.\n",
       "3.  **Superior Business Agility:** Companies can react to market shifts and competitor moves with unprecedented speed, exploiting fleeting opportunities.\n",
       "4.  **Proactive Problem Solving:** Many issues can be mitigated or resolved before users even notice them, leading to a more stable and reliable product.\n",
       "5.  **Optimized Resource Utilization:** Human developers can focus on higher-level strategic planning, complex architectural challenges, and creative innovation, offloading repetitive or urgent tactical work to RADA.\n",
       "6.  **Continuous Improvement:** The system continuously learns and adapts, leading to a steadily improving codebase and product.\n",
       "\n",
       "RADA transforms the reactive, often slow, human-centric software development process into a real-time, adaptive, and highly autonomous ecosystem, directly tackling the lag in responding to dynamic product performance and user needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then read the business idea:\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"This is a business area that might be worth exploring for an Agentic AI opportunity: {area}. This is a pain-point in that industry - something challenging that might be ripe for an Agentic solution: {pain_point}. Please propose an Agentic AI solution.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "\n",
    "solution = response.choices[0].message.content\n",
    "display(Markdown(solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
